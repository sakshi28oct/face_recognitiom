{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca504be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Sakshi\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import  numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2434f3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import array_to_img, ImageDataGenerator, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1ecabdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GenerateImage= ImageDataGenerator(rotation_range=40, width_shift_range= .2, height_shift_range=.2, shear_range=.2,\n",
    "                                  zoom_range=.2,horizontal_flip=True, fill_mode='nearest' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "882559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img= load_img(r\"C:\\Users\\Sakshi\\Downloads\\WhatsApp Image 2023-11-28 at 23.11.39 (1).jpeg\")\n",
    "x=img_to_array(img)\n",
    "# to generate the image we need to load the img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dea6e94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1280, 720, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=x.reshape((1,)+ x.shape)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0425bce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "i= 0\n",
    "for batch in GenerateImage.flow(x, batch_size=1, save_to_dir=\"d:\\preveiw\", save_prefix='dd', save_format='JPG'):\n",
    "    \n",
    "    i=i+1\n",
    "    if i>100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90e4eaa",
   "metadata": {},
   "source": [
    "#  model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "886899c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D,Flatten, Dense,Dropout,AvgPool2D\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Lambda, Flatten, Input\n",
    "from keras.preprocessing  import image\n",
    "from keras.models import Sequential\n",
    "import glob\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "218d5183",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size=200\n",
    "\n",
    "path1=r\"D:\\face_recognition\" # path of folder\n",
    "cate =[\"suraj\",\"sakshi\"]# picture containing folder\n",
    "input_image=[]\n",
    "for i in cate:\n",
    "    folders=os.path.join(path1,i)\n",
    "    label= cate.index(i)\n",
    "    for image in os.listdir(folders):\n",
    "        image_path= os.path.join(folders,image)\n",
    "        image_array= cv2.imread(image_path)\n",
    "        image_array=cv2.resize(image_array,(image_size,image_size))\n",
    "        input_image.append([image_array,label])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55fe56d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c4550be",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(input_image) # every time run the code shuffling is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92d3f1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[]\n",
    "y=[]\n",
    "\n",
    "for x_values,labels in input_image:\n",
    "    x.append(x_values)\n",
    "    y.append(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1a54dca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array(x)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "803844f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c9287288",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x[:300]\n",
    "y_train = y[:300]\n",
    "\n",
    "x_test = x[300:400]\n",
    "y_test = y[300:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81181cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255\n",
    "x_test = x_test/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1313fce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "521e6e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(Conv2D(filters=50,kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu',input_shape=x_train.shape[1:]))\n",
    "model.add(Dense(2,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f41bc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f72fc60e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\Sakshi\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Sakshi\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "6/6 [==============================] - 22s 2s/step - loss: 14.4342 - accuracy: 0.5233\n",
      "Epoch 2/5\n",
      "6/6 [==============================] - 13s 2s/step - loss: 1.1303 - accuracy: 0.7067\n",
      "Epoch 3/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.3388 - accuracy: 0.8400\n",
      "Epoch 4/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.1211 - accuracy: 0.9833\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 12s 2s/step - loss: 0.1241 - accuracy: 0.9600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x277d9311050>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train, epochs=5,batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bae33e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0e32423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 178ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(x_train)\n",
    "pred_final= pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e6b075b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       152\n",
      "           1       1.00      0.91      0.95       148\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,pred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef50f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 169ms/step\n"
     ]
    }
   ],
   "source": [
    "pred_t=model.predict(x_test)\n",
    "pred_final_t= pred_t.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8318e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        46\n",
      "           1       1.00      0.81      0.90        54\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.91      0.91      0.90       100\n",
      "weighted avg       0.92      0.90      0.90       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred_final_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "95828d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"face_recognitio.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c083654e",
   "metadata": {},
   "source": [
    "#  working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06474697",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade= cv2.CascadeClassifier(r\"D:\\open cv\\HaarCascade\\HaarCascade\\haarcascade_frontalface_default.xml\")\n",
    "def face_detection(img):\n",
    "    face_img=img.copy()\n",
    "    \n",
    "    face_reacts=face_cascade.detectMultiScale(face_img)# this face is just x,y,height and breath of rectangle\n",
    "    \n",
    "    for(x,y,w,h) in face_reacts:\n",
    "        cv2.rectangle(face_img,(x,y),(x+w,y+h),(255,0,0),3)# frawing rectangle on face\n",
    "    return face_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cd67a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_cascade = cv2.CascadeClassifier(r\"C:\\Users\\Sakshi\\HaarCascade\\HaarCascade\\haarcascade_eye.xml\")\n",
    "\n",
    "def eye_detection(img):\n",
    "    face_img = img.copy()\n",
    "    eye_rects =  eye_cascade.detectMultiScale(face_img) \n",
    "    for (x,y,w,h) in eye_rects:\n",
    "        cv2.rectangle(face_img, (x,y), (x+w, y+h), (255,100,10),5)\n",
    "    return face_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "80a545e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 335ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('face_recognitio.h5')\n",
    "results={0:'suraj',  1:'sakshi'}\n",
    "GR_dict={0:(0,255,255),1:(0,255,0)}\n",
    "\n",
    "rect_size = 4\n",
    "cap = cv2.VideoCapture(0)\n",
    "haarcascade = cv2.CascadeClassifier(r\"D:\\open cv\\HaarCascade\\HaarCascade\\haarcascade_frontalface_default.xml\")\n",
    "while True:\n",
    "    (rval, im) = cap.read()\n",
    "    im=cv2.flip(im,1,1) \n",
    "\n",
    "    \n",
    "    rerect_size = cv2.resize(im, (im.shape[1] // rect_size, im.shape[0] // rect_size))\n",
    "    faces = haarcascade.detectMultiScale(rerect_size)\n",
    "    for f in faces:\n",
    "        (x, y, w, h) = [v * rect_size for v in f] \n",
    "        \n",
    "        face_img = im[y:y+h, x:x+w]\n",
    "        rerect_sized=cv2.resize(face_img,(200,200))\n",
    "        normalized=rerect_sized/255.0\n",
    "        reshaped=np.reshape(normalized,(1,200,200,3))\n",
    "        reshaped = np.vstack([reshaped])\n",
    "        result=model.predict(reshaped)\n",
    "        \n",
    "        label=np.argmax(result,axis=1)[0]\n",
    "      \n",
    "        cv2.rectangle(im,(x,y),(x+w,y+h),GR_dict[label],2)\n",
    "        cv2.rectangle(im,(x,y-40),(x+w,y),GR_dict[label],-1)\n",
    "        cv2.putText(im, results[label], (x, y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,0,0),2)\n",
    "\n",
    "    cv2.imshow('Liv Camera',   im)\n",
    "    key = cv2.waitKey(10)\n",
    "    \n",
    "    if key == 27: # use the escape key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9741d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
